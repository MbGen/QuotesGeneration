{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7adb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bcccac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8ef678",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('quotes.txt', sep='\\t', header=None, names=['quotes'])\n",
    "df = df.map(lambda x: re.sub('[.,]', '', x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81cdf167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.vocab as vocab\n",
    "\n",
    "glove = vocab.GloVe(name='6B', dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79555a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quotes_enc'] = df['quotes'].map(lambda w: [glove.stoi.get(i, 1) for i in w.split()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "246dab1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69498"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for enc_quote in df['quotes_enc']:\n",
    "    for ix in enc_quote:\n",
    "        data.append(ix)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06673653",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_data = torch.tensor(data).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "db4faf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  171,     5, 16942,    59,   185, 19423,     1,    36]],\n",
      "       device='cuda:0')\n",
      "tensor([[    5, 16942,    59,   185, 19423,     1,    36,   285]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "batch_size = 1\n",
    "\n",
    "def build_train_test_dataset(data, train_size_percent, block_size, batch_size):\n",
    "    \n",
    "    n = int(train_size_percent / 10 * len(data))\n",
    "    \n",
    "    train_data = data[:n]\n",
    "    val_data = data[n:]\n",
    "    \n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    \n",
    "    return x, y\n",
    "    \n",
    "    \n",
    "X, Y = build_train_test_dataset(tensor_data, 70, block_size, batch_size) \n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b21033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lower_tril_from(original_matrix):\n",
    "    triangular_matrix = torch.tril(original_matrix.repeat(original_matrix.size(1), 1), diagonal=0)\n",
    "    return triangular_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "783ac5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее количество обучаемых параметров в модели: 60407600\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.embedings = nn.Embedding.from_pretrained(glove.vectors)\n",
    "        self.num_features = glove.dim\n",
    "        self.num_layers_rnn = 1\n",
    "        self.num_directions_rnn = 1 # if 2 means prediction of past and future\n",
    "        self.hidden_size = self.num_features // 2\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size=self.num_features,\n",
    "                          hidden_size=self.hidden_size,\n",
    "                          num_layers=self.num_layers_rnn,\n",
    "                          batch_first=True).to(device)\n",
    "        \n",
    "        self.fc = nn.Linear(50, len(glove)).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, targets):\n",
    "        B, T, C = x.shape\n",
    "        \n",
    "        h0 = torch.zeros(self.num_layers_rnn * self.num_directions_rnn, \n",
    "                         B,\n",
    "                         self.hidden_size,\n",
    "                         requires_grad=True).to(device)\n",
    "        \n",
    "        x = self.embedings(x)\n",
    "        x = x.view(B, T, -1)\n",
    "        \n",
    "        out, hidden = self.rnn(x, h0)\n",
    "        \n",
    "        out = out.view(-1, 50)\n",
    "        \n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        loss = F.cross_entropy(out, targets)\n",
    "        \n",
    "        return out, hidden, loss\n",
    "        \n",
    "\n",
    "model = RNN().to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Общее количество обучаемых параметров в модели: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9905a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3000\n",
    "lr = 0.00001\n",
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "958de938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(12.8978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(12.7545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(12.9384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(12.8135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(13.0635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(12.6672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(12.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(12.4818, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[0;32m---> 18\u001b[0m     lossi\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     19\u001b[0m loss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train = True\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    inp, actual = build_train_test_dataset(tensor_data, 70, block_size, batch_size)\n",
    "    inp = inp.unsqueeze(-1)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    out, hidden, loss = model(inp, actual)\n",
    "    \n",
    "    loss.backward()\n",
    "        \n",
    "    optimizer.step()\n",
    "    if epoch % 300 == 0:\n",
    "        print(loss)\n",
    "    lossi.append(loss.item())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2fb42e17",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 100]' is invalid for input of size 20921",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlossi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 100]' is invalid for input of size 20921"
     ]
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 100).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1de1e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval = True\n",
    "hidden = torch.zeros(2, 1, 100).to(device)\n",
    "inp = glove.stoi['the']\n",
    "k = 3\n",
    "context = []\n",
    "context.append(inp)\n",
    "for i in range(20):\n",
    "    out, hidden = model(torch.tensor(context.copy()).to(device), hidden)\n",
    "    topk_values, topk_indices = torch.topk(out, k)\n",
    "    sampled_index = torch.multinomial(F.softmax(topk_values, dim=0), 1)\n",
    "    context.append(topk_indices[0][sampled_index[0].item()].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0422f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the same mentality 1960s his american world world kids world same 1960s mentality family pleasure addict world world crafts sign metric'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(map(lambda x: glove.itos[x], [i for i in context]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecc022bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
